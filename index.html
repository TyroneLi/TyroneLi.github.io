<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />

<title>Jinlong Li</title>

</head>
<body>

<!-- Project
<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#services">Services</a> 
<a href="#awards">Awards</a>  
</div>
 -->

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 


<table class="imgtable"><tr><td>
<a href="./"><img src="./files/photo.jpeg" alt="" height="250px" /></a>&nbsp;</td>
<td align="left"><p><font size="5">Jinlong Li (李金龙)</font><br />
<br />
<a href="https://about.meituan.com/">Meituan Inc.</a><br />
 Vision Department, <a href="https://about.meituan.com/" target="_blank">Researcher</a><br />
<br />
District Longhua, Shenzhen, Guangdong, China<br />

<br />
Email: jinlong.szu@gmail.com <br />
<!-- [<a class="p1" href="https://scholar.google.com/citations?user=hpEAymEAAAAJ&hl=zh-CN&authuser=1" target="_blank">Google Scholar</a>]  -->
<!-- [<a class="p2" href="https://github.com/TyroneLi" target="_blank">Github</a>] -->
<p>
  <a href="https://github.com/TyroneLi"><img src="./index_files/github.png" height="30px"></a>
  <a href="https://scholar.google.com/citations?user=hpEAymEAAAAJ&hl=zh-CN&authuser=1"><img src="./index_files/google_scholar.png" height="30px"></a>
</p>
</p>
</td></tr></table>

<h2>Biography</h2>
<p> 
  I am now working at <a href="https://about.meituan.com/">MeiTuan</a> as a computer vision engineer, currently studying closely with <a href="https://forestlinma.com/">Dr. Lin Ma</a> 
  and <a href="https://scholar.google.com/citations?user=4sKGNB0AAAAJ&hl=zh-CN">Dr. Zequn Jie</a>, focusing on Weakly/Semi-supervised 2D/3D detection and segmentation. 
  Before that, I obtained my B.Sc and M.Sc degree in <a href="https://en.szu.edu.cn/">Shenzhen University</a>.
</p>


<h2>Research Interest</h2>
I work in the field of Computer Vision and Deep Learning. Recently, I focus on the following research topics:
<ul>
<li>Label-Efficient Learning</li>
<li>Multi-Modal Perception and Reasoning Learning</li>
<li>Generative Models</li>
<li>Foundation Models</li>
</ul>


	
<!-- <h2>PyTorch Toolbox for Image Restoration</h2>
<ul>
<li> <a href="https://github.com/cszn/KAIR" target="_blank">KAIR</a> (support training and testing for DnCNN, FFDNet, SRMD, USRNet, ESRGAN) </li>
<li> <a href="https://github.com/cszn/DPIR" target="_blank">DPIR</a> (Plug-and-Play Image Restoration with Deep Denoiser Prior)</li>
</ul> -->


<h2>News</h2>
<ul>

  <li>
    2023 Mar: Served as a reviewer for <a href="https://openreview.net/group?id=NeurIPS.cc/2023/Conference/">NeurIPS 2023</a>.
  </li>

  <li>
    2023 Feb: One paper got accepted by <a href="https://www.editorialmanager.com/neucom/">Neurocomputing 2023</a>!
  </li>

  <li>
    2023 Feb: Served as a reviewer for <a href="https://openreview.net/group?id=ICML.cc/2023/Conference/">ICML 2023</a>.
  </li>

  <li>
    2023 Jan: Served as a reviewer for <a href="https://openreview.net/group?id=thecvf.com/CVPR/2023/Conference/">CVPR 2023</a>.
  </li>

  <li>
    2022 Sept: Our work <a href="http://arxiv.org/abs/2209.07761/">ESOL</a> got accepted by <a href="https://nips.cc/">NeurIPS 2022</a>!
  </li>

  <li>
    2022 Feb: Our work <a href="https://ieeexplore.ieee.org/document/9716799">PPL</a> got accepted by <a href="https://ieeexplore.ieee.org/document/9716799">TMM 2022</a>!
  </li>

</ul>

	
<!-- Project -->
<a id="publications" class="anchor"></a>
<h2>Publications</h2>

<table class="imgtable">

<!-- NEUCOM 2022-->
<tr>
<td><img class="proj_thumb" src="./files/NEURALCOM_2023_SSDL.png" alt="" height="200px"/>&nbsp;</td>
<td>
<p class="pub_title">Weakly Supervised Semantic Segmentation via Self-Supervised Destruction Learning</p>
<p class="pub_author"><b>Jinlong Li</b>, Zequn Jie, Xu Wang, Yu Zhou, Lin Ma, Jianming Jiang<br>
  Neurocomputing</i> (<b>NEUCOM</b>), 2023.<br>
  <font color="#FF0000">Abstract: In this paper, we propose a novel “destruction learning” method via self-supervised manner,
    producing the CAM attention maps better covering the whole object rather than only the most discriminative regions
    as previous approaches. Region destruction mechanism is proposed to deliberately “destruct” the global structure in
    both mid-level and low-level feature learning following jigsaw puzzle operation, for better local feature extraction of
    the classification network.</font>
</p> </td>
</tr>

<!-- NeurIPS 2022-->
<tr>
  <td><img class="proj_thumb" src="./files/esol_intro1.png" alt="" height="200px"/>&nbsp;</td>
  <td>
  <p class="pub_title">Expansion and Shrinkage of Localization for Weakly-Supervised Semantic Segmentation</p>
  <p class="pub_author"><b>Jinlong Li</b>, Zequn Jie, Xu Wang, Xiaolin Wei, Lin Ma<br>
    Neural Information Processing Systems (<b>NeurIPS</b>), </em> <b>Spotlight (1.7%)</b> 2022.<br>
  [<a href="http://arxiv.org/abs/2209.07761/">ArXiv Link</a>]
  [<a href="https://github.com/TyroneLi/ESOL_WSSS">Code</a>]<br>
  <!-- [<a href="bibtex.html#zhang2022practical" target="_blank">BibTex</a>] -->
  <font color="#FF0000">Abstract: We propose a new training pipeline to alleviate the partial localization 
    issue of the CAM in Weakly-supervised image semantic segmentation, ESOL, in a Divide-and-Conquer manner.</font>
  </p> </td>
  </tr>

<!-- TMM 2022-->
<tr>
  <td><img class="proj_thumb" src="./files/ppl_intro1.png" alt="" height="200px"/>&nbsp;</td>
  <td>
  <p class="pub_title">Weakly Supervised Semantic Segmentation via Progressive Patch Learning</p>
  <p class="pub_author"><b>Jinlong Li</b>, Zequn Jie, Xu Wang, Yu Zhou, Xiaolin Wei, Lin Ma<br>
    IEEE Transactions on Multimedia (<b>TMM</b>), </em>2022.<br>
  [<a href="hhttps://arxiv.org/abs/2209.07828/">ArXiv Link</a>]
  [<a href="https://ieeexplore.ieee.org/document/9716799/">IEEE Trans Link</a>]
  [<a href="https://github.com/TyroneLi/PPL_WSSS">Code</a>]<br>
  <!-- [<a href="bibtex.html#zhang2022practical" target="_blank">BibTex</a>] -->
  <font color="#FF0000">Abstract: We propose a new training pipeline to alleviate the partial localization issue of 
    the CAM in Weakly-supervised image semantic segmentation, PPL, in an iterative training manner.</font>
  </p> </td>
  </tr>

<table>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>

<!-- <p>Workshop Organizers: </p>
<font size="2">
<ul>
<li><p>Co-organizer of ECCV 2020 Workshop on Advanced Image Manipulation (AIM). </p></li>
<li><p>Co-organizer of CVPR 2020 Workshop on New Trends in Image Restoration and Enhancement (NTIRE). </p></li>
<li><p>Co-organizer of ICCV 2019 Workshop on Advanced Image Manipulation (AIM). </p></li>
</ul>
</font> -->

 
<p>Journal Reviewer:  </p>
<font size="3"> 
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
<!-- <li>International Journal of Computer Vision (IJCV)</li> -->
<!-- <li>IEEE Transactions on Image Processing (TIP)</li> -->
<!-- <li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li> -->
<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
<!-- <li>Computer Vision and Image Understanding (CVIU)</li> -->
<!-- <li>Signal Processing Letters (SPL)</li> -->
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="3"> 
<ul>
  <li>Neural Information Processing Systems (NeurIPS)</li>
  <li>International Conference on Machine Learning (ICML)</li>
  <li>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</li>
  <li>International Conference on Computer Vision (ICCV)</li>
  <li>European Conference on Computer Vision (ECCV)</li>
</ul>
</font>


<!-- awards -->
<a id="awards" class="achor"></a>
<h2>Awards</h2>
<font size="3"> 
<ul>
<li>Outstanding student paper award of SZU, 2023</li>
</ul>
</font>


<!-- Links 
<h2>Music</h2>
<iframe width="280" height="157" src="https://www.youtube.com/embed/-5qhNRmMilI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>	
<iframe width="280" height="157" src="https://www.youtube.com/embed/AVXejOoPECA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
<iframe width="280" height="157" src="https://www.youtube.com/embed/xTRVZbHjmbc" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>	
-->
	
<!-- <div align="center">
	<body> 
		<font color="gray">&copy Jinlong Li</font>
	</body> 
</div> -->

	
<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<div align=""center>
<!-- <a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a> -->
  <a href="https://info.flagcounter.com/xnxJ"><img src="https://s11.flagcounter.com/mini/xnxJ/bg_FFFFFF/txt_000000/border_CCCCCC/flags_0/" alt="Flag Counter" border="0"></a>
</div>div>

<div align="center">
	<body> 
		<font color="gray">&copy Jinlong Li</font>
	</body> 
</div>

</body>
</html>
